{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Definition-to-Neologism Generation\n",
        "\n",
        "This project is inspired by the research of my professor, Paul Lerner, as outlined in his paper [Towards Machine Translation of Scientific Neologisms](https://aclanthology.org/2024.jeptalnrecital-taln.17/). While the paper itself is in French, an abstract in English provides insight into its objectives:\n",
        "\n",
        "> Scientific research continually discovers and invents new concepts, which are then referred to by new terms, neologisms, or neonyms in this context. As the vast majority of publications are written in English, disseminating this new knowledge in French often requires translating these terms, to avoid multiplying anglicisms that are less easily understood by the general public. We propose to explore this task using two thesauri, exploiting the definition of the term to translate it more accurately. To this end, we explore the capabilities of two large multilingual models, BLOOM and CroissantLLM, which can translate scientific terms to some extent. In particular, we show that they often use appropriate morphological procedures, but are limited by the segmentation into sub-lexical units. They are also biased by the frequency of term occurrences and surface similarities between English and French.\n",
        "\n",
        "For my task, I am focusing on the \"DEF\" setting, which simplifies the problem as follows: given a definition, the goal is to generate the term that corresponds to it. I will evaluate the generated outputs using Exact Match, meaning the generated term must exactly match the reference.\n",
        "\n",
        "For example:\n",
        "- **Input**: \"Having to do with the ability to transmit data in either direction.\"\n",
        "- **Expected Output**: \"bidirectional.\"\n",
        "\n",
        "In this case, \"bidirectional\" is formed by prefixing \"bi-\" to \"directional,\" itself derived by suffixing \"-al\" to \"direction,\" which is present in the input definition. This project emphasizes understanding and modeling such morphological and linguistic patterns to achieve accurate term generation.\n"
      ],
      "metadata": {
        "id": "G8v63BJ-hCVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation and imports\n"
      ],
      "metadata": {
        "id": "ebec84ad-2e31-4cc2-8bb5-63c07c3e0006"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# Suppress all warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-04T01:29:03.869038Z",
          "iopub.execute_input": "2024-11-04T01:29:03.869481Z",
          "iopub.status.idle": "2024-11-04T01:29:03.880792Z",
          "shell.execute_reply.started": "2024-11-04T01:29:03.869437Z",
          "shell.execute_reply": "2024-11-04T01:29:03.879870Z"
        },
        "trusted": true,
        "id": "FejgCgnN4I-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "qJ8dHbLzfgSq",
        "outputId": "4105cfcf-d65e-44db-b51b-0f497ad1cc77",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:29:03.882460Z",
          "iopub.execute_input": "2024-11-04T01:29:03.882788Z",
          "iopub.status.idle": "2024-11-04T01:29:05.010836Z",
          "shell.execute_reply.started": "2024-11-04T01:29:03.882755Z",
          "shell.execute_reply": "2024-11-04T01:29:05.009698Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Mon Nov  4 01:29:04 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   37C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   37C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "8dyC55OX4I-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "gather": {
          "logged": 1730652440907
        },
        "id": "4_g1yxfefP2r",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:29:05.012406Z",
          "iopub.execute_input": "2024-11-04T01:29:05.012812Z",
          "iopub.status.idle": "2024-11-04T01:29:08.933107Z",
          "shell.execute_reply.started": "2024-11-04T01:29:05.012766Z",
          "shell.execute_reply": "2024-11-04T01:29:08.932269Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert torch.cuda.is_available(), \"Connect to GPU and try again\""
      ],
      "metadata": {
        "gather": {
          "logged": 1730652441129
        },
        "id": "a-9phz_EfQ2d",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:29:08.935674Z",
          "iopub.execute_input": "2024-11-04T01:29:08.936490Z",
          "iopub.status.idle": "2024-11-04T01:29:08.991626Z",
          "shell.execute_reply.started": "2024-11-04T01:29:08.936444Z",
          "shell.execute_reply": "2024-11-04T01:29:08.990672Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data\n",
        "\n",
        "I will restrict to the TERMIUM dataset, which provides definitions in both English and French.  \n",
        "I will use only English definitions so that I am all able to judge the generations (in case I don't speak French).  \n",
        "Therefore, the numbers will not be comparable to my paper, although I can have a rough idea."
      ],
      "metadata": {
        "id": "ld22ogMkhCVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/ANR-MaTOS/termium/raw/refs/heads/main/termium.json.zip"
      ],
      "metadata": {
        "id": "uQPCPIt_hCVg",
        "outputId": "e1e2959d-fba0-47b5-86e7-f2238e13d33b",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:29:08.992786Z",
          "iopub.execute_input": "2024-11-04T01:29:08.993100Z",
          "iopub.status.idle": "2024-11-04T01:29:10.576735Z",
          "shell.execute_reply.started": "2024-11-04T01:29:08.993050Z",
          "shell.execute_reply": "2024-11-04T01:29:10.575778Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "--2024-11-04 01:29:09--  https://github.com/ANR-MaTOS/termium/raw/refs/heads/main/termium.json.zip\nResolving github.com (github.com)... 140.82.114.3\nConnecting to github.com (github.com)|140.82.114.3|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/ANR-MaTOS/termium/refs/heads/main/termium.json.zip [following]\n--2024-11-04 01:29:10--  https://raw.githubusercontent.com/ANR-MaTOS/termium/refs/heads/main/termium.json.zip\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 75145939 (72M) [application/zip]\nSaving to: 'termium.json.zip'\n\ntermium.json.zip    100%[===================>]  71.66M   237MB/s    in 0.3s    \n\n2024-11-04 01:29:10 (237 MB/s) - 'termium.json.zip' saved [75145939/75145939]\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip termium.json.zip"
      ],
      "metadata": {
        "id": "FUktoagRhCVg",
        "outputId": "aa0273df-b6cd-4a12-8615-fde1de5b674a",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:29:37.954554Z",
          "iopub.execute_input": "2024-11-04T01:29:37.955476Z",
          "iopub.status.idle": "2024-11-04T01:29:42.028670Z",
          "shell.execute_reply.started": "2024-11-04T01:29:37.955434Z",
          "shell.execute_reply": "2024-11-04T01:29:42.027706Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Archive:  termium.json.zip\n  inflating: termium.json            \n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "gather": {
          "logged": 1730652441434
        },
        "id": "RRhkSGBYhCVh",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:29:52.814195Z",
          "iopub.execute_input": "2024-11-04T01:29:52.814908Z",
          "iopub.status.idle": "2024-11-04T01:29:52.819316Z",
          "shell.execute_reply.started": "2024-11-04T01:29:52.814869Z",
          "shell.execute_reply": "2024-11-04T01:29:52.818476Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"termium.json\",\"rt\") as file:\n",
        "    data = json.load(file)"
      ],
      "metadata": {
        "gather": {
          "logged": 1730652441456
        },
        "id": "MSJfIc9KhCVi",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:29:52.820998Z",
          "iopub.execute_input": "2024-11-04T01:29:52.821269Z",
          "iopub.status.idle": "2024-11-04T01:30:11.076114Z",
          "shell.execute_reply.started": "2024-11-04T01:29:52.821239Z",
          "shell.execute_reply": "2024-11-04T01:30:11.075291Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset has three subsets. Make sure to use:\n",
        "- the train set to fine-tune your models\n",
        "- the dev set for any hyperparameter tuning, e.g. how long do you fine-tune\n",
        "- the test set only for final evaluation"
      ],
      "metadata": {
        "id": "Vb0D3Z-xhCVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in data.items():\n",
        "    print(k, len(v))"
      ],
      "metadata": {
        "gather": {
          "logged": 1730652002337
        },
        "id": "it8DsTzdhCVi",
        "outputId": "2ea97266-44ea-4a6d-cd57-c7197eaa67e3",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:11.077786Z",
          "iopub.execute_input": "2024-11-04T01:30:11.078129Z",
          "iopub.status.idle": "2024-11-04T01:30:11.083388Z",
          "shell.execute_reply.started": "2024-11-04T01:30:11.078095Z",
          "shell.execute_reply": "2024-11-04T01:30:11.082330Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "dev 5000\ntrain 1158299\ntest 5001\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data inspection\n",
        "item = data[\"train\"][1000]\n",
        "\n"
      ],
      "metadata": {
        "gather": {
          "logged": 1730652002707
        },
        "id": "AGScX2jahCVj",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:11.084542Z",
          "iopub.execute_input": "2024-11-04T01:30:11.085018Z",
          "iopub.status.idle": "2024-11-04T01:30:11.095213Z",
          "shell.execute_reply.started": "2024-11-04T01:30:11.084985Z",
          "shell.execute_reply": "2024-11-04T01:30:11.094292Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two fields your are interested in: English definition (input), and English term (target)"
      ],
      "metadata": {
        "id": "sPUvLEjwhCVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "item[\"en\"][\"def\"][\"text\"]   # Definition text"
      ],
      "metadata": {
        "gather": {
          "logged": 1730652002984
        },
        "id": "kF56JC3KhCVj",
        "outputId": "3ec042f6-1f44-4df3-f39a-e4963e6b34f7",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:11.097233Z",
          "iopub.execute_input": "2024-11-04T01:30:11.097855Z",
          "iopub.status.idle": "2024-11-04T01:30:11.108176Z",
          "shell.execute_reply.started": "2024-11-04T01:30:11.097819Z",
          "shell.execute_reply": "2024-11-04T01:30:11.107316Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'The inadvertent and irrecoverable loss of nuclear material in an accident.'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "item[\"en\"][\"text\"]    # Target term"
      ],
      "metadata": {
        "gather": {
          "logged": 1730652003669
        },
        "id": "17Wnm2pXhCVj",
        "outputId": "00c65e4b-a920-4196-84ab-ac0277332e7b",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:11.109286Z",
          "iopub.execute_input": "2024-11-04T01:30:11.109658Z",
          "iopub.status.idle": "2024-11-04T01:30:11.121291Z",
          "shell.execute_reply.started": "2024-11-04T01:30:11.109601Z",
          "shell.execute_reply": "2024-11-04T01:30:11.120360Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'accidental loss'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that most examples in the training set do not provide a definition. Make sure to filter them! You should end up with 200K definitions or so."
      ],
      "metadata": {
        "id": "LUuQ9hrahCVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"train\"][0][\"en\"][\"def\"]"
      ],
      "metadata": {
        "gather": {
          "logged": 1730652003869
        },
        "id": "w_786-IPhCVk",
        "outputId": "87e917d8-9c84-482c-8229-29eb2d68fb29",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:11.122390Z",
          "iopub.execute_input": "2024-11-04T01:30:11.122713Z",
          "iopub.status.idle": "2024-11-04T01:30:11.131351Z",
          "shell.execute_reply.started": "2024-11-04T01:30:11.122674Z",
          "shell.execute_reply": "2024-11-04T01:30:11.130416Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'text': None}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning: Filter Entries with Definitions"
      ],
      "metadata": {
        "id": "b4KmhjPQ5gn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter entries with definitions for train, dev, and test sets\n",
        "filtered_train_data = [entry for entry in data[\"train\"] if \"def\" in entry[\"en\"]]\n",
        "filtered_dev_data = [entry for entry in data[\"dev\"] if \"def\" in entry[\"en\"]]\n",
        "filtered_test_data = [entry for entry in data[\"test\"] if \"def\" in entry[\"en\"]]\n",
        "\n",
        "print(\"Filtered Train Set Size:\", len(filtered_train_data))\n",
        "print(\"Filtered Dev Set Size:\", len(filtered_dev_data))\n",
        "print(\"Filtered Test Set Size:\", len(filtered_test_data))\n"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651992692
        },
        "id": "WrKu97yo5jek",
        "outputId": "07a473a3-b172-48a5-a711-792debbe3495",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:11.132384Z",
          "iopub.execute_input": "2024-11-04T01:30:11.132674Z",
          "iopub.status.idle": "2024-11-04T01:30:11.531812Z",
          "shell.execute_reply.started": "2024-11-04T01:30:11.132618Z",
          "shell.execute_reply": "2024-11-04T01:30:11.530874Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Filtered Train Set Size: 1158299\nFiltered Dev Set Size: 5000\nFiltered Test Set Size: 5001\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I will compare two models in this project:\n",
        "- [mT5](https://aclanthology.org/2021.naacl-main.41/), an encoder-decoder trained on a multilingual corpus, which uses BPE tokenization\n",
        "- [ByT5](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00461/110049/ByT5-Towards-a-Token-Free-Future-with-Pre-trained), the same architecture and corpus, except that it is a *byte-level model* (i.e. *character-level model* for languages that use latin script/ASCII)\n",
        "\n"
      ],
      "metadata": {
        "id": "nIfw5gYhhCVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Tokenizers for mT5 and ByT5 Models"
      ],
      "metadata": {
        "id": "MI5TCL0j5xSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import T5Model, MT5Model, T5TokenizerFast, AutoTokenizer\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651992964
        },
        "id": "SXGj8UpGhCVk",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:11.532942Z",
          "iopub.execute_input": "2024-11-04T01:30:11.533222Z",
          "iopub.status.idle": "2024-11-04T01:30:29.295505Z",
          "shell.execute_reply.started": "2024-11-04T01:30:11.533191Z",
          "shell.execute_reply": "2024-11-04T01:30:29.294489Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mt5_tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\", legacy=False)\n"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651993214
        },
        "id": "j9urZXO9hCVk",
        "outputId": "a35035b2-340e-4815-80c3-e6de6719a974",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:29.296783Z",
          "iopub.execute_input": "2024-11-04T01:30:29.297364Z",
          "iopub.status.idle": "2024-11-04T01:30:34.016811Z",
          "shell.execute_reply.started": "2024-11-04T01:30:29.297322Z",
          "shell.execute_reply": "2024-11-04T01:30:34.015820Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "f5b6283d76fc486d825f93898fb28cc0",
            "020a3c9c594e4eaabbdbdfab77ac643a",
            "a0c16c13b15a413985e6fd716d5af65b",
            "1d4761677fdc424196f19ae783970730"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/82.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5b6283d76fc486d825f93898fb28cc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/553 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "020a3c9c594e4eaabbdbdfab77ac643a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0c16c13b15a413985e6fd716d5af65b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d4761677fdc424196f19ae783970730"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that, when using BPE, a prefixation will deteriorate the segmentation.\n",
        "\n",
        "\n",
        "\"bidirectional\" is segmented as `'▁bi', 'direction', 'al'` and therefore does not share a representation with its base, `'▁direction'` (which is different from `'direction'`, an intra-word token).\n",
        "\n",
        "See the reference paper (if you can read French) or https://aclanthology.org/2021.acl-long.279/"
      ],
      "metadata": {
        "id": "Z8gQ-aN1hCVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[mt5_tokenizer.tokenize(token) for token in [\"bidirectional\", \"directional\", \"direction\"]]"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651993486
        },
        "id": "U33at7TlhCVl",
        "outputId": "6e295fd8-2136-4a19-c44e-d93f553ab6c2",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:34.021303Z",
          "iopub.execute_input": "2024-11-04T01:30:34.021637Z",
          "iopub.status.idle": "2024-11-04T01:30:34.032917Z",
          "shell.execute_reply.started": "2024-11-04T01:30:34.021603Z",
          "shell.execute_reply": "2024-11-04T01:30:34.031991Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[['▁bi', 'direction', 'al'], ['▁direction', 'al'], ['▁direction']]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This does not mean that the segmentation of suffixes is perfect either!\n",
        "\n",
        "See here, for example, \"generalization\" does not share any representation from its base \"generalize\", as they are segmented differently."
      ],
      "metadata": {
        "id": "gORfc9rihCVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[mt5_tokenizer.tokenize(token) for token in [\"generalize\", \"generalization\"]]"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651993751
        },
        "id": "mm9WwfLUhCVm",
        "outputId": "5ba02579-bb1f-41e8-8fef-46c56994ffec",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:34.034227Z",
          "iopub.execute_input": "2024-11-04T01:30:34.034618Z",
          "iopub.status.idle": "2024-11-04T01:30:34.107945Z",
          "shell.execute_reply.started": "2024-11-04T01:30:34.034575Z",
          "shell.execute_reply": "2024-11-04T01:30:34.106954Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[['▁generaliz', 'e'], ['▁general', 'ization']]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is one of the main goals of this project: will byte-level model outperform a BPE-based model? If yes, is it because the byte-level model is better at modeling morphology?"
      ],
      "metadata": {
        "id": "SYK8kTx_hCVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "byt5_tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-small\", legacy=False)\n"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651994013
        },
        "id": "oM0v-_UMhCVm",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:34.109210Z",
          "iopub.execute_input": "2024-11-04T01:30:34.109770Z",
          "iopub.status.idle": "2024-11-04T01:30:34.871478Z",
          "shell.execute_reply.started": "2024-11-04T01:30:34.109726Z",
          "shell.execute_reply": "2024-11-04T01:30:34.870618Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "f77bd8e86e2a476a950083f309803b7f",
            "a4bea692d411460998a13afa8fec9470",
            "4661a020a5e04cf2a3c077067ae5826f"
          ]
        },
        "outputId": "9abb536c-b239-4f4e-ac9d-64f69aac4e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/2.59k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f77bd8e86e2a476a950083f309803b7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/698 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4bea692d411460998a13afa8fec9470"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/2.50k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4661a020a5e04cf2a3c077067ae5826f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With a byte-level models, \"bidirectional\" shares all letters from its base \"directional\". I see two main drawbacks, what are they?"
      ],
      "metadata": {
        "id": "s4glwahRhCVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[byt5_tokenizer.tokenize(token) for token in [\"bidirectional\", \"directional\", \"direction\"]]"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651994267
        },
        "id": "rVLEibPchCVm",
        "outputId": "5c22b1ea-5af0-4430-b12e-3d024d4e05ae",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:34.872784Z",
          "iopub.execute_input": "2024-11-04T01:30:34.873167Z",
          "iopub.status.idle": "2024-11-04T01:30:34.881032Z",
          "shell.execute_reply.started": "2024-11-04T01:30:34.873123Z",
          "shell.execute_reply": "2024-11-04T01:30:34.879710Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[['b', 'i', 'd', 'i', 'r', 'e', 'c', 't', 'i', 'o', 'n', 'a', 'l'],\n ['d', 'i', 'r', 'e', 'c', 't', 'i', 'o', 'n', 'a', 'l'],\n ['d', 'i', 'r', 'e', 'c', 't', 'i', 'o', 'n']]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize Data for Training"
      ],
      "metadata": {
        "id": "QtKDqEG26SG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare training data\n",
        "inputs_mt5 = []\n",
        "targets_mt5 = []\n",
        "inputs_byt5 = []\n",
        "targets_byt5 = []\n",
        "\n",
        "# Filter and prepare training data\n",
        "for item in data[\"train\"]:\n",
        "    if \"def\" in item[\"en\"] and item[\"en\"][\"def\"] and \"text\" in item[\"en\"][\"def\"]:\n",
        "        definition = item[\"en\"][\"def\"][\"text\"]\n",
        "        term = item[\"en\"][\"text\"]\n",
        "\n",
        "        inputs_mt5.append(definition)\n",
        "        targets_mt5.append(term)\n",
        "        inputs_byt5.append(definition)\n",
        "        targets_byt5.append(term)"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651994524
        },
        "id": "jkhzHQVlAMFC",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:34.882683Z",
          "iopub.execute_input": "2024-11-04T01:30:34.883024Z",
          "iopub.status.idle": "2024-11-04T01:30:36.429035Z",
          "shell.execute_reply.started": "2024-11-04T01:30:34.882986Z",
          "shell.execute_reply": "2024-11-04T01:30:36.428234Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n"
      ],
      "metadata": {
        "id": "C3CdrbciiuLU",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:36.430112Z",
          "iopub.execute_input": "2024-11-04T01:30:36.430400Z",
          "iopub.status.idle": "2024-11-04T01:30:36.435175Z",
          "shell.execute_reply.started": "2024-11-04T01:30:36.430370Z",
          "shell.execute_reply": "2024-11-04T01:30:36.434054Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DefinitionTermDataset(Dataset):\n",
        "    def __init__(self, inputs, targets, tokenizer, max_length=512):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Add a prefix to make it clear this is a definition-to-term task\n",
        "        input_text = f\"Generate term: {self.inputs[idx]}\"\n",
        "        target_text = self.targets[idx]\n",
        "\n",
        "        # Tokenize inputs and targets\n",
        "        model_inputs = self.tokenizer(\n",
        "            input_text,\n",
        "            max_length=self.max_length,\n",
        "            padding=False,  # Let the data collator handle padding\n",
        "            truncation=True,\n",
        "        )\n",
        "\n",
        "        # Tokenize targets\n",
        "        with self.tokenizer.as_target_tokenizer():\n",
        "            labels = self.tokenizer(\n",
        "                target_text,\n",
        "                max_length=self.max_length,\n",
        "                padding=False,  # Let the data collator handle padding\n",
        "                truncation=True,\n",
        "            )\n",
        "\n",
        "        model_inputs['labels'] = labels['input_ids']\n",
        "        return model_inputs"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651995044
        },
        "id": "ctiBu_Hm6kVI",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:36.436395Z",
          "iopub.execute_input": "2024-11-04T01:30:36.436682Z",
          "iopub.status.idle": "2024-11-04T01:30:36.556393Z",
          "shell.execute_reply.started": "2024-11-04T01:30:36.436628Z",
          "shell.execute_reply": "2024-11-04T01:30:36.555457Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset objects\n",
        "train_dataset_mt5 = DefinitionTermDataset(inputs_mt5, targets_mt5, mt5_tokenizer)\n",
        "train_dataset_byt5 = DefinitionTermDataset(inputs_byt5, targets_byt5, byt5_tokenizer)"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651995303
        },
        "id": "WmfA_1mqAML0",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:36.557540Z",
          "iopub.execute_input": "2024-11-04T01:30:36.557931Z",
          "iopub.status.idle": "2024-11-04T01:30:36.567387Z",
          "shell.execute_reply.started": "2024-11-04T01:30:36.557899Z",
          "shell.execute_reply": "2024-11-04T01:30:36.566665Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "BfZZGCRsLWjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models and tokenizers\n",
        "mt5_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-small\")\n"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651995558
        },
        "id": "aXQiHmPLhCVm",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:36.568399Z",
          "iopub.execute_input": "2024-11-04T01:30:36.568720Z",
          "iopub.status.idle": "2024-11-04T01:30:46.092341Z",
          "shell.execute_reply.started": "2024-11-04T01:30:36.568688Z",
          "shell.execute_reply": "2024-11-04T01:30:46.091451Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "7e6cd61c4a0b40fab2d7cd5d08a989b8",
            "75c7bc469e6f40f1a837febd5f5479e2"
          ]
        },
        "outputId": "f6f63b51-fed9-4237-dcf8-3d435c90a80b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e6cd61c4a0b40fab2d7cd5d08a989b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75c7bc469e6f40f1a837febd5f5479e2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data collators\n",
        "mt5_data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=mt5_tokenizer,\n",
        "    model=mt5_model,\n",
        "    padding=True\n",
        ")"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651995820
        },
        "id": "wFVOv661kEOF",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:46.093677Z",
          "iopub.execute_input": "2024-11-04T01:30:46.093993Z",
          "iopub.status.idle": "2024-11-04T01:30:46.098290Z",
          "shell.execute_reply.started": "2024-11-04T01:30:46.093961Z",
          "shell.execute_reply": "2024-11-04T01:30:46.097273Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mt5_model"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651996082
        },
        "id": "kZpkStL0hCVm",
        "outputId": "607eff1d-9d19-4286-9571-8fc0d04262df",
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:46.099504Z",
          "iopub.execute_input": "2024-11-04T01:30:46.099882Z",
          "iopub.status.idle": "2024-11-04T01:30:46.175835Z",
          "shell.execute_reply.started": "2024-11-04T01:30:46.099850Z",
          "shell.execute_reply": "2024-11-04T01:30:46.174905Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 30,
          "output_type": "execute_result",
          "data": {
            "text/plain": "MT5ForConditionalGeneration(\n  (shared): Embedding(250112, 512)\n  (encoder): MT5Stack(\n    (embed_tokens): Embedding(250112, 512)\n    (block): ModuleList(\n      (0): MT5Block(\n        (layer): ModuleList(\n          (0): MT5LayerSelfAttention(\n            (SelfAttention): MT5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 6)\n            )\n            (layer_norm): MT5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): MT5LayerFF(\n            (DenseReluDense): MT5DenseGatedActDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): MT5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-7): 7 x MT5Block(\n        (layer): ModuleList(\n          (0): MT5LayerSelfAttention(\n            (SelfAttention): MT5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): MT5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): MT5LayerFF(\n            (DenseReluDense): MT5DenseGatedActDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): MT5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): MT5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): MT5Stack(\n    (embed_tokens): Embedding(250112, 512)\n    (block): ModuleList(\n      (0): MT5Block(\n        (layer): ModuleList(\n          (0): MT5LayerSelfAttention(\n            (SelfAttention): MT5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 6)\n            )\n            (layer_norm): MT5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): MT5LayerCrossAttention(\n            (EncDecAttention): MT5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): MT5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): MT5LayerFF(\n            (DenseReluDense): MT5DenseGatedActDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): MT5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-7): 7 x MT5Block(\n        (layer): ModuleList(\n          (0): MT5LayerSelfAttention(\n            (SelfAttention): MT5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): MT5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): MT5LayerCrossAttention(\n            (EncDecAttention): MT5Attention(\n              (q): Linear(in_features=512, out_features=384, bias=False)\n              (k): Linear(in_features=512, out_features=384, bias=False)\n              (v): Linear(in_features=512, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=512, bias=False)\n            )\n            (layer_norm): MT5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): MT5LayerFF(\n            (DenseReluDense): MT5DenseGatedActDense(\n              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n              (wo): Linear(in_features=1024, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): MT5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): MT5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=250112, bias=False)\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "byt5_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/byt5-small\")\n"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651996342
        },
        "id": "HcnuF0ahhCVm",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:46.176943Z",
          "iopub.execute_input": "2024-11-04T01:30:46.177225Z",
          "iopub.status.idle": "2024-11-04T01:30:54.048329Z",
          "shell.execute_reply.started": "2024-11-04T01:30:46.177193Z",
          "shell.execute_reply": "2024-11-04T01:30:54.047455Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "33303c013ba24effbb89d47e8052f43d",
            "1969f20bf87e4b1b9a3bfdc7a42b95c2"
          ]
        },
        "outputId": "9465d621-2d96-4c9b-bec0-34b3614cae13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33303c013ba24effbb89d47e8052f43d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1969f20bf87e4b1b9a3bfdc7a42b95c2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "byt5_data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=byt5_tokenizer,\n",
        "    model=byt5_model,\n",
        "    padding=True\n",
        ")\n"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651996595
        },
        "id": "zgTkJhvMkH23",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:54.049687Z",
          "iopub.execute_input": "2024-11-04T01:30:54.050066Z",
          "iopub.status.idle": "2024-11-04T01:30:54.054973Z",
          "shell.execute_reply.started": "2024-11-04T01:30:54.050020Z",
          "shell.execute_reply": "2024-11-04T01:30:54.053931Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "byt5_model"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651996856
        },
        "id": "D3EtNaPyhCVm",
        "outputId": "864593fd-f527-41ba-c925-c75f110281a6",
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:54.055994Z",
          "iopub.execute_input": "2024-11-04T01:30:54.056249Z",
          "iopub.status.idle": "2024-11-04T01:30:55.946565Z",
          "shell.execute_reply.started": "2024-11-04T01:30:54.056221Z",
          "shell.execute_reply": "2024-11-04T01:30:55.945524Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 33,
          "output_type": "execute_result",
          "data": {
            "text/plain": "T5ForConditionalGeneration(\n  (shared): Embedding(384, 1472)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(384, 1472)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=1472, out_features=384, bias=False)\n              (k): Linear(in_features=1472, out_features=384, bias=False)\n              (v): Linear(in_features=1472, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=1472, bias=False)\n              (relative_attention_bias): Embedding(32, 6)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=1472, out_features=3584, bias=False)\n              (wi_1): Linear(in_features=1472, out_features=3584, bias=False)\n              (wo): Linear(in_features=3584, out_features=1472, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=1472, out_features=384, bias=False)\n              (k): Linear(in_features=1472, out_features=384, bias=False)\n              (v): Linear(in_features=1472, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=1472, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=1472, out_features=3584, bias=False)\n              (wi_1): Linear(in_features=1472, out_features=3584, bias=False)\n              (wo): Linear(in_features=3584, out_features=1472, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(384, 1472)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=1472, out_features=384, bias=False)\n              (k): Linear(in_features=1472, out_features=384, bias=False)\n              (v): Linear(in_features=1472, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=1472, bias=False)\n              (relative_attention_bias): Embedding(32, 6)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=1472, out_features=384, bias=False)\n              (k): Linear(in_features=1472, out_features=384, bias=False)\n              (v): Linear(in_features=1472, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=1472, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=1472, out_features=3584, bias=False)\n              (wi_1): Linear(in_features=1472, out_features=3584, bias=False)\n              (wo): Linear(in_features=3584, out_features=1472, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-3): 3 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=1472, out_features=384, bias=False)\n              (k): Linear(in_features=1472, out_features=384, bias=False)\n              (v): Linear(in_features=1472, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=1472, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=1472, out_features=384, bias=False)\n              (k): Linear(in_features=1472, out_features=384, bias=False)\n              (v): Linear(in_features=1472, out_features=384, bias=False)\n              (o): Linear(in_features=384, out_features=1472, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=1472, out_features=3584, bias=False)\n              (wi_1): Linear(in_features=1472, out_features=3584, bias=False)\n              (wo): Linear(in_features=3584, out_features=1472, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=1472, out_features=384, bias=False)\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Training Arguments with Memory Optimization"
      ],
      "metadata": {
        "id": "IK1oJIhG6zfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training arguments for mT5 with memory optimization\n",
        "training_args_mt5 = TrainingArguments(\n",
        "    output_dir=\"./mt5-results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=1,        # Reduce batch size to minimize memory usage\n",
        "    gradient_accumulation_steps=1,        # No gradient accumulation\n",
        "    num_train_epochs=1,                   # Fewer epochs to reduce training time\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True,                            # Enable mixed-precision training (float16)\n",
        "    gradient_checkpointing=False,         # Explicitly disable gradient checkpointing\n",
        "    logging_dir=\"./logs\",\n",
        ")\n"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651997116
        },
        "id": "1_UM5MDO6vxU",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:55.948267Z",
          "iopub.execute_input": "2024-11-04T01:30:55.948733Z",
          "iopub.status.idle": "2024-11-04T01:30:56.102559Z",
          "shell.execute_reply.started": "2024-11-04T01:30:55.948690Z",
          "shell.execute_reply": "2024-11-04T01:30:56.101711Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training arguments for ByT5 with memory optimization\n",
        "training_args_byt5 = TrainingArguments(\n",
        "    output_dir=\"./byt5-results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=1,        # Reduce batch size to minimize memory usage\n",
        "    gradient_accumulation_steps=1,        # No gradient accumulation\n",
        "    num_train_epochs=1,                   # Fewer epochs to reduce training time\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True,                            # Enable mixed-precision training (float16)\n",
        "    gradient_checkpointing=False,         # Explicitly disable gradient checkpointing\n",
        "    logging_dir=\"./logs\",\n",
        ")"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651997372
        },
        "id": "QYBRKA9T6v0X",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:56.103832Z",
          "iopub.execute_input": "2024-11-04T01:30:56.104199Z",
          "iopub.status.idle": "2024-11-04T01:30:56.140952Z",
          "shell.execute_reply.started": "2024-11-04T01:30:56.104157Z",
          "shell.execute_reply": "2024-11-04T01:30:56.140188Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "sqxKJop6669q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_mt5 = Trainer(\n",
        "    model=mt5_model,\n",
        "    args=training_args_mt5,\n",
        "    train_dataset=train_dataset_mt5,\n",
        "    data_collator=mt5_data_collator,\n",
        ")\n"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651997635
        },
        "id": "NVpCe9rE6v3e",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:56.141990Z",
          "iopub.execute_input": "2024-11-04T01:30:56.142254Z",
          "iopub.status.idle": "2024-11-04T01:30:57.684387Z",
          "shell.execute_reply.started": "2024-11-04T01:30:56.142225Z",
          "shell.execute_reply": "2024-11-04T01:30:57.683665Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_mt5.train()"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651997896
        },
        "id": "HcpRPGfX6wJH",
        "outputId": "54568fdb-ecb9-4816-bbc1-bc908139ef33",
        "execution": {
          "iopub.status.busy": "2024-11-04T01:30:57.685427Z",
          "iopub.execute_input": "2024-11-04T01:30:57.685756Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "398bec3baeb54542923536631d2f7d00"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "  ········································\n"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113694888889667, max=1.0…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "398bec3baeb54542923536631d2f7d00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.18.3"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241104_013116-65ffo0ua</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/esp1/huggingface/runs/65ffo0ua' target=\"_blank\">./mt5-results</a></strong> to <a href='https://wandb.ai/esp1/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/esp1/huggingface' target=\"_blank\">https://wandb.ai/esp1/huggingface</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/esp1/huggingface/runs/65ffo0ua' target=\"_blank\">https://wandb.ai/esp1/huggingface/runs/65ffo0ua</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='60430' max='579150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 60430/579150 8:13:45 < 70:38:31, 2.04 it/s, Epoch 0.10/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainer_byt5 = Trainer(\n",
        "    model=byt5_model,\n",
        "    args=training_args_byt5,\n",
        "    train_dataset=train_dataset_byt5,\n",
        "    data_collator=byt5_data_collator,"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651998160
        },
        "id": "W_DmaCMn6wMG",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_byt5.train()"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651998500
        },
        "id": "BWvzMgyv6wPl",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "3vYqa3ek7LCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "def tune_hyperparameters(model_name, tokenizer, base_model, train_data, dev_data):\n",
        "    param_grid = {\n",
        "        'learning_rate': [1e-4, 3e-4, 5e-4],\n",
        "        'batch_size': [4, 8],\n",
        "        'num_epochs': [2, 3]\n",
        "    }\n",
        "\n",
        "    best_score = 0\n",
        "    best_params = None\n",
        "\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        print(f\"\\nTrying parameters: {params}\")\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=f\"./{model_name}-tuning\",\n",
        "            learning_rate=params['learning_rate'],\n",
        "            per_device_train_batch_size=params['batch_size'],\n",
        "            num_train_epochs=params['num_epochs'],\n",
        "            evaluation_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            load_best_model_at_end=True,\n",
        "            fp16=True,\n",
        "        )\n",
        "\n",
        "        # Create trainer with current parameters\n",
        "        trainer = Trainer(\n",
        "            model=base_model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_data,\n",
        "            eval_dataset=dev_data,\n",
        "            data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, model=base_model),\n",
        "        )\n",
        "\n",
        "        # Train and evaluate\n",
        "        trainer.train()\n",
        "        eval_results = trainer.evaluate()\n",
        "        current_score = eval_results['eval_loss']\n",
        "\n",
        "        if current_score > best_score:\n",
        "            best_score = current_score\n",
        "            best_params = params\n",
        "\n",
        "    return best_params\n"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651998850
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "trusted": true,
        "id": "eLCn6SmI4I_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare test data\n",
        "def prepare_test_data(data, tokenizer):\n",
        "    test_inputs = []\n",
        "    test_targets = []\n",
        "\n",
        "    for item in data[\"test\"]:\n",
        "        if \"def\" in item[\"en\"] and item[\"en\"][\"def\"] and \"text\" in item[\"en\"][\"def\"]:\n",
        "            definition = item[\"en\"][\"def\"][\"text\"]\n",
        "            term = item[\"en\"][\"text\"]\n",
        "            test_inputs.append(definition)\n",
        "            test_targets.append(term)\n",
        "\n",
        "    return DefinitionTermDataset(test_inputs, test_targets, tokenizer)\n",
        "\n",
        "# Define Exact Match calculation\n",
        "def calculate_exact_match(predictions, targets):\n",
        "    matches = sum(1 for pred, target in zip(predictions, targets) if pred.strip() == target.strip())\n",
        "    return matches / len(targets) if len(targets) > 0 else 0\n",
        "\n",
        "# Generate predictions and evaluate\n",
        "def evaluate_model(model, tokenizer, test_dataset):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    targets = []\n",
        "\n",
        "    for item in tqdm(test_dataset):\n",
        "        input_ids = item['input_ids'].unsqueeze(0).to(model.device)\n",
        "        attention_mask = item['attention_mask'].unsqueeze(0).to(model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=50,\n",
        "                num_beams=4,\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        target = tokenizer.decode(item['labels'], skip_special_tokens=True)\n",
        "\n",
        "        predictions.append(pred)\n",
        "        targets.append(target)\n",
        "\n",
        "    exact_match = calculate_exact_match(predictions, targets)\n",
        "    return exact_match, predictions\n"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651999179
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "trusted": true,
        "id": "2Z1KQIya4I_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Main evaluation pipeline\n",
        "def run_evaluation():\n",
        "    # Prepare test data\n",
        "    test_dataset_mt5 = prepare_test_data(data, mt5_tokenizer)\n",
        "    test_dataset_byt5 = prepare_test_data(data, byt5_tokenizer)\n",
        "\n",
        "    # Tune hyperparameters using dev set\n",
        "    print(\"Tuning mT5...\")\n",
        "    best_params_mt5 = tune_hyperparameters(\n",
        "        'mt5',\n",
        "        mt5_tokenizer,\n",
        "        mt5_model,\n",
        "        train_dataset_mt5,\n",
        "        test_dataset_mt5\n",
        "    )\n",
        "\n",
        "    print(\"Tuning ByT5...\")\n",
        "    best_params_byt5 = tune_hyperparameters(\n",
        "        'byt5',\n",
        "        byt5_tokenizer,\n",
        "        byt5_model,\n",
        "        train_dataset_byt5,\n",
        "        test_dataset_byt5\n",
        "    )\n",
        "\n",
        "    # Evaluate on test set\n",
        "    print(\"\\nEvaluating models on test set...\")\n",
        "    exact_match_mt5, predictions_mt5 = evaluate_model(mt5_model, mt5_tokenizer, test_dataset_mt5)\n",
        "    exact_match_byt5, predictions_byt5 = evaluate_model(byt5_model, byt5_tokenizer, test_dataset_byt5)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\nResults:\")\n",
        "    print(f\"mT5 Exact Match: {exact_match_mt5:.4f}\")\n",
        "    print(f\"ByT5 Exact Match: {exact_match_byt5:.4f}\")\n",
        "\n",
        "    # Analysis\n",
        "    if exact_match_byt5 > exact_match_mt5:\n",
        "        print(\"\\nByT5 outperforms mT5 on morphological generation tasks.\")\n",
        "        print(\"This suggests that character-level modeling is more effective for this task.\")\n",
        "    else:\n",
        "        print(\"\\nmT5 outperforms ByT5 or performs similarly.\")\n",
        "        print(\"This suggests that subword tokenization is sufficient for this task.\")\n",
        "\n",
        "    # Error analysis\n",
        "    print(\"\\nError Analysis:\")\n",
        "    for i in range(min(5, len(predictions_mt5))):\n",
        "        print(f\"\\nExample {i+1}:\")\n",
        "        print(f\"Input: {test_dataset_mt5[i]['input_ids']}\")\n",
        "        print(f\"Target: {test_dataset_mt5[i]['labels']}\")\n",
        "        print(f\"mT5 prediction: {predictions_mt5[i]}\")\n",
        "        print(f\"ByT5 prediction: {predictions_byt5[i]}\")\n"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651999519
        },
        "id": "JRJogjf77M0A",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Run the evaluation\n",
        "run_evaluation()"
      ],
      "metadata": {
        "gather": {
          "logged": 1730651999848
        },
        "id": "F5YgphD97M2-",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}